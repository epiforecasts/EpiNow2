---
title: "Speeding up model runs"
output:
  rmarkdown::html_vignette   
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
vignette: >
  %\VignetteIndexEntry{Speeding up model runs}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---




``` r
library(EpiNow2)
library(scoringutils)
library(data.table)
library(rstan)
library(cmdstanr)
library(ggplot2)
```

This vignette explores available forecasting model options in _EpiNow2_ and how they vary by speed and forecast performance. We will compare the models by run time and forecast performance (quantitatively and qualitatively) against the "true" trajectory of the data.

## The benchmarking data

To compare the model options, we will need a dataset for which we know the "true" values and trajectories. So, we will start by generating the "true" infections and Rt data using _EpiNow2_'s `forecast_infections()` function. 

`forecast_infections()` requires a fitted estimates object from `estimate_infections()` or `epinow()`, the trajectory of the reproduction number, `R`, and the number of samples to simulate. So, we will set these up first.

To obtain the `estimates` object, we will run the `estimate_infections()` model using real-world observed data and delay distributions to recover realistic parameter values. We will use the first 100 observations of the `example_confirmed` data set, the `example_generation_time`, `example_incubation_period`, and `example_reporting_delay` values that come with _EpiNow2_.

Several of the parameters we will use throughout this vignette will have the same value, so we will set them up here in one place.

``` r
# Set the number of cores to use
options(mc.cores = 4)

# Generation time
generation_time <- Gamma(
  shape = Normal(1.3, 0.3),
  rate = Normal(0.37, 0.09),
  max = 14
)

# Incubation period
incubation_period <- LogNormal(
  meanlog = Normal(1.6, 0.05),
  sdlog = Normal(0.5, 0.05),
  max = 14
)

# Reporting delay
reporting_delay <- LogNormal(
  meanlog = 0.5,
  sdlog = 0.5,
  max = 10
)

# Combine the incubation period and reporting delay into one delay
delay <- incubation_period + reporting_delay

# Observation model options
obs <- obs_opts(
  scale = list(mean = 0.1, sd = 0.025),
  return_likelihood = TRUE
)

# Forecast horizon
horizon <- 0
```

Now, let's generate the `estimates` object.

``` r
estimates <- estimate_infections(
  example_confirmed[1:100],
  generation_time = generation_time_opts(example_generation_time),
  delays = delay_opts(example_incubation_period + example_reporting_delay),
  rt = rt_opts(prior = list(mean = 2, sd = 0.1), rw = 14),
  gp = NULL,
  obs = obs,
  horizon = horizon
)
```

```
#> DEBUG [2024-06-13 20:11:11] estimate_infections: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 114 time steps of which 0 are a forecast
```

For the `R` data, we will set up an arbitrary trajectory and add some Gaussian noise.

``` r
# Arbitrary reproduction number trajectory
R <- c(
  rep(2, 40), rep(0.5, 10), rep(1, 10), 1 + 0.04 * 1:20, rep(1.4, 5),
  1.4 - 0.02 * 1:20, rep(1.4, 10), rep(0.8, 5), 0.8 + 0.02 * 1:20
)
# Add Gaussian noise
R_noisy <- R * rnorm(length(R), 1, 0.05)
```

Now, we will simulate the true infections and $Rt$ data by sampling from $10$ posterior samples.

``` r
# Forecast infections and the trajectory of Rt
forecast <- forecast_infections(estimates, R = R_noisy, samples = 10)
```

```
#> DEBUG [2024-06-13 20:11:46] simulate_infections: Running in exact mode for 1 samples (across 1 chains each with a warm up of 1 iterations each) and 154 time steps of which 40 are a forecast
```

We will now extract the benchamrking data:
- `R_true`: the median of the simulated $Rt$, and
- `infections_true`: the infections by date of infection


``` r
R_true <- forecast$summarised[variable == "R"]$median

# Get the posterior samples from which to extract the simulated infections and reported cases
posterior_sample <- forecast$samples[sample == 1]

# Extract the simulated infections
infections_true <- posterior_sample[variable == "infections"]$value

# Extract the simulated reported cases and rename the "value" column to "confirm" (to match EpiNow2 requirements)
reported_cases_true <- posterior_sample[
  variable == "reported_cases", .(date, confirm = value)
]
```

Now, to the main part of this vignette: we will compare the run times of different model options.

## Model options

We will use the following models:
- _gp_: A Gaussian process prior on the reproduction number $R_t$ and no random walk, using _MCMC sampling_.
- _vb_: A Gaussian process prior on the reproduction number $R_t$ and no random walk, using the _variational inference_ algorithm.
- _non_mechanistic_: A model with that uses _back calculation and sets no prior on $R_t$.
- _rw1_no_gp_: A model with a 1-day random walk and Gaussian process turned off.
- _rw7_no_gp_: A model with a 7-day random walk and Gaussian process turned off.
- _rw7_gp_: A model with a 7-day random walk and Gaussian process turned on.
- _pf_: A model that uses the "pathfinder" algorithm (from the [`{cmdstanr}`](https://github.com/stan-dev/cmdstanr) package) for sampling.
- _lp_: A model that uses the "Laplace" algorithm (from the [`{cmdstanr}`](https://github.com/stan-dev/cmdstanr) package) for sampling.


``` r
models <- list(
  gp = list(
    rt = rt_opts(prior = list(mean = 2, sd = 0.1))
  )
  ,
  # The non-mechanistic model
  non_mechanistic = list(rt = NULL),
  # The model with a 1-day random walk and Gaussian process turned off
  rw1_no_gp = list(
    rt = rt_opts(
      prior = list(mean = 2, sd = 0.1),
        rw = 1
      ),
    gp = NULL
  ),
  # The model with a 7-day random walk and Gaussian process turned off
  rw7_no_gp = list(
    rt = rt_opts(
      prior = list(mean = 2, sd = 0.1),
        rw = 7
      ),
    gp = NULL
  ),
  # The model with a 7-day random walk and Gaussian process (default)
  rw7_gp = list(
    rt = rt_opts(
      prior = list(mean = 2, sd = 0.1),
      rw = 7,
      gp_on = "R0"
    )
  ),
  # Model that uses the variational inference method instead of MCMC
  vb = list(
    stan = stan_opts(
      method = "vb",
      trials = 5,
      samples = 2000
    )
  )#,
  # The model that uses "pathfinder" approximate sampling from `cmdstanr` package
  # pathfinder = list(
  #   stan = stan_opts(
  #     method = "pathfinder",
  #     backend = "cmdstanr",
  #     trials = 5,
  #     samples = 2000
  #   )
  # ),
  # # The model that uses Laplace approximate sampling from `cmdstanr` package
  # laplace = list(
  #   stan = stan_opts(
  #     method = "laplace",
  #     backend = "cmdstanr",
  #     trials = 5,
  #     samples = 2000
  #   )
  # )
)
```

## Running the models

Let's run the models and gather the results. We will sweep across the list of models `models` and shared model options `model_inputs`. We will use the `epinow()` function which is a wrapper around `estimate_infections()` and returns useful outputs like the timing of model runs.

``` r
model_inputs <- list(
  data = reported_cases_true,
  generation_time = generation_time_opts(generation_time),
  delays = delay_opts(delay),
  obs = obs,
  horizon = horizon
)
# Run the models
results <- lapply(
  models,
  function(model) {
    do.call(
      epinow,
      c(
        model_inputs,
        model
      )
    )
  }
)
```

```
#> WARN [2024-06-13 20:11:46] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:11:46] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:11:46] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:11:46] epinow: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 154 time steps of which 0 are a forecast
#> WARN [2024-06-13 20:16:43] epinow: There were 37 divergent transitions after warmup. See
#> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#> to find out why this is a problem and how to eliminate them. - 
#> WARN [2024-06-13 20:16:43] epinow: Examine the pairs() plot to diagnose sampling problems
#>  - 
#> WARN [2024-06-13 20:16:46] epinow: NAs introduced by coercion to integer range - .f, .x[[i]], ...
#> WARN [2024-06-13 20:16:46] epinow: NAs introduced by coercion to integer range - .f, .x[[i]], ...
#> WARN [2024-06-13 20:16:47] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:16:47] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:16:47] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:16:47] epinow: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 147 time steps of which 0 are a forecast
#> WARN [2024-06-13 20:17:00] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:17:00] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:17:00] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:17:00] epinow: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 154 time steps of which 0 are a forecast
#> WARN [2024-06-13 20:22:57] epinow: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
#> Running the chains for more iterations may help. See
#> https://mc-stan.org/misc/warnings.html#bulk-ess - 
#> WARN [2024-06-13 20:22:57] epinow: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
#> Running the chains for more iterations may help. See
#> https://mc-stan.org/misc/warnings.html#tail-ess - 
#> WARN [2024-06-13 20:22:58] epinow: NAs introduced by coercion to integer range - .f, .x[[i]], ...
#> WARN [2024-06-13 20:22:59] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:22:59] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:22:59] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:22:59] epinow: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 154 time steps of which 0 are a forecast
#> WARN [2024-06-13 20:25:23] epinow: NAs introduced by coercion to integer range - .f, .x[[i]], ...
#> WARN [2024-06-13 20:25:23] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:25:23] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:25:23] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:25:23] epinow: Running in exact mode for 2000 samples (across 4 chains each with a warm up of 250 iterations each) and 154 time steps of which 0 are a forecast
#> WARN [2024-06-13 20:31:38] epinow: NAs introduced by coercion to integer range - .f, .x[[i]], ...
#> WARN [2024-06-13 20:31:39] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:31:39] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> WARN [2024-06-13 20:31:39] epinow: partial match of 'length' to 'lengths' - $, consecutive, length
#> DEBUG [2024-06-13 20:31:39] epinow: Running in approximate mode for 10000 iterations (with 5 attempts). Extracting 2000 approximate posterior samples for 154 time steps of which 0 are a forecast
#> Chain 1: ------------------------------------------------------------
#> Chain 1: EXPERIMENTAL ALGORITHM:
#> Chain 1:   This procedure has not been thoroughly tested and may be unstable
#> Chain 1:   or buggy. The interface is subject to change.
#> Chain 1: ------------------------------------------------------------
#> Chain 1: 
#> Chain 1: 
#> Chain 1: 
#> Chain 1: Gradient evaluation took 0.000129 seconds
#> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.29 seconds.
#> Chain 1: Adjust your expectations accordingly!
#> Chain 1: 
#> Chain 1: 
#> Chain 1: Begin eta adaptation.
#> Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
#> Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
#> Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
#> Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
#> Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
#> Chain 1: Success! Found best value [eta = 1] earlier than expected.
#> Chain 1: 
#> Chain 1: Begin stochastic gradient ascent.
#> Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
#> Chain 1:    100      -268499.784             1.000            1.000
#> Chain 1:    200        -7761.034            17.298           33.596
#> Chain 1:    300        -2335.360            12.306            2.323
#> Chain 1:    400        -1532.517             9.361            2.323
#> Chain 1:    500        -1347.813             7.516            1.000
#> Chain 1:    600        -1288.467             6.271            1.000
#> Chain 1:    700        -1177.122             5.389            0.524
#> Chain 1:    800        -1158.795             4.717            0.524
#> Chain 1:    900        -1154.629             4.193            0.137
#> Chain 1:   1000        -1148.537             3.775            0.137
#> Chain 1:   1100        -1231.497             3.681            0.095   MAY BE DIVERGING... INSPECT ELBO
#> Chain 1:   1200        -1149.984             0.329            0.071
#> Chain 1:   1300        -1143.163             0.097            0.067
#> Chain 1:   1400        -1154.361             0.046            0.046
#> Chain 1:   1500        -1165.635             0.033            0.016
#> Chain 1:   1600        -1196.434             0.031            0.016
#> Chain 1:   1700        -1148.639             0.026            0.016
#> Chain 1:   1800        -1150.040             0.024            0.010   MEDIAN ELBO CONVERGED
#> Chain 1: 
#> Chain 1: Drawing a sample of size 2000 from the approximate posterior... 
#> Chain 1: COMPLETED.
#> WARN [2024-06-13 20:31:40] epinow: partial match of 'log_p' to 'log_p__' - $, diagnostics, log_p
#> WARN [2024-06-13 20:31:40] epinow: partial match of 'log_g' to 'log_g__' - $, diagnostics, log_g
#> WARN [2024-06-13 20:31:40] epinow: Pareto k diagnostic value is 2. Resampling is disabled. Decreasing tol_rel_obj may help if variational algorithm has terminated prematurely. Otherwise consider using sampling instead. -
```

## Evaluating performance

### Run times

Let's see how long each model took to run. Note that the run time measured here uses a crude method that compares the start and end times of each simulation. It is meant to be approximate and may not be accurate. For accurate run times, we recommend using a more sophisticated benchmarking tool like `bench` or `microbenchmark`.


``` r
# Extract the run times
models <- names(models)
runtimes <- vapply(
  results,
  function(x) x$timing,
  double(1)
)
# Extracting the difftime objects drops the units, so we need to extract them separately
runtimes_units <- vapply(
  results,
  function(x) attr(x$timing, "units"),
  character(1)
)
# We then recompose the runtimes with the units
runtimes_vec <- paste(round(runtimes), runtimes_units)
# Add the model names
names(runtimes_vec) <- models
# Print in table
knitr::kable(runtimes_vec, col.names = c("models", "Run time"), caption = "Run times")
```



Table: Run times (seconds)

|models          |  Run time|
|:---------------|---------:|
|gp              |  5.011109|
|non_mechanistic | 13.676094|
|rw1_no_gp       |  5.972183|
|rw7_no_gp       |  2.413113|
|rw7_gp          |  6.252660|
|vb              |  2.673222|

### Forecast evaluation

Now, we will compare the estimated and true values using the continuous ranked probability score (CRPS). The CRPS is a proper scoring rule that measures the accuracy of probabilistic forecasts. We will use the `crps()` function from the `{scoringutils}` package.

To calculate the CRPS for the estimated $R_t$ and infections, we will first set up a function that makes sure the data and estimates are of the same length and calls the `crps_sample()` function from the `{scoringutils}` package.

``` r
# A function to calculate the CRPS
calc_crps <- function(x, truth) {
  shortest_obs_length <- min(ncol(x), length(truth))
  reduced_truth <- tail(truth, shortest_obs_length)
  reduced_x <- tail(t(x), shortest_obs_length)
  return(crps_sample(reduced_truth, reduced_x))
}
```

Now, we can calculate CRPS for the $R_t$ and infection estimates of the various models using `calc_crps()`.


``` r
# Get the Rt samples
Rt_estimated <- lapply(results, function(x) {
  if ("R[1]" %in% names(x$estimates$fit)) {
    extract(x$estimates$fit, "R")$R
  } else {
    extract(x$estimates$fit, "gen_R")$gen_R
  }
})
# CRPS for the Rt estimates
rt_crps <- lapply(
  Rt_estimated,
  calc_crps,
  truth = R
)

# Get the infection samples
infections_estimated <- lapply(results, function(x) {
  extract(x$estimates$fit, "infections")$infections
})

# CRPS for the infections estimates
infections_crps <- lapply(
  infections_estimated,
  calc_crps,
  truth = infections_true
)
```

We will now post-process the CRPS results to make them easier to visualise.


``` r
# Post-processing the CRPS results of the Rt estimates
rt_df <- as.data.table(rt_crps)
rt_df[, metric := "CRPS"]
rt_df[, time := 1:.N]
rt_df <- melt(
  rt_df,
  id.vars = c("metric", "time"),
  variable.name = "model"
)

# Post-processing the CRPS results of the infection estimates
infections_df <- as.data.table(infections_crps)
infections_df[, metric := "CRPS"]
infections_df[, time := 1:.N]
infections_df <- melt(
  infections_df,
  id.vars = c("metric", "time"),
  variable.name = "model"
)
```

Let's visualise the CRPS results for the Rt and infection estimates.


``` r
rt_plot <- ggplot(rt_df, aes(x = time, y = value, colour = model)) +
  geom_line() +
  scale_colour_brewer("Model", palette = "Dark2") +
  xlab("Time") +
  ylab("CRPS") +
  ggplot2::theme_bw() +
  ggtitle("Reconstructing R")
plot(rt_plot)
```

![plot of chunk rt_plot](figure/rt_plot-1.png)


``` r
infections_plot <- ggplot(infections_df, aes(x = time, y = value, colour = model)) +
  geom_line() +
  scale_colour_brewer("Model", palette = "Dark2") +
  xlab("Time") +
  ylab("CRPS") +
  ggplot2::theme_bw() +
  ggtitle("Reconstructing infections")
plot(infections_plot)
```

![plot of chunk infections_plot](figure/infections_plot-1.png)

## Some considerations when using the model options

### Mechanistic vs non-mechanistic models

- Estimation in _EpiNow2_ using the mechanistic approaches (prior on Rt) is often much slower than the non- mechanistic approach. The mechanistic model is slower because it models intricate details about the processes and mechanisms that drive $Rt$ estimates. The nonmechanistic model, on the other hand, is faster because it does not model these intricate details. If performing a retrospective analysis, the _non-mechanistic model_ (where `rt = NULL`) is better suited and a faster alternative to the mechanistic $Rt$ model.

### Exact vs approximate methods

- The default method is `method = "sampling"`, which performs MCMC sampling. The MCMC sampling method is accurate but can often be slow. The Laplace, Pathfinder, and variational inference methods are the fastest because they are approximate methods. The first two require having the `cmdstanr` package installed. Also note that the methods are experimental and may not be as reliable as the default MCMC sampling method. For details on the Laplace and Pathfinder approximation methods, see respectively, [here](https://mc-stan.org/docs/cmdstan-guide/laplace_sample_config.html) and [here](https://mc-stan.org/docs/cmdstan-guide/pathfinder_config.html).

### Granularity of estimates

- The random walk method reduces granularity in estimates, compared to the other methods.
